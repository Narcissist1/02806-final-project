{
  
    
        "post0": {
            "title": "Social Graph Final project",
            "content": ". Important: The dataset we were used to create the network comes from Twitter, you can view and download them from here. The Explainer notebook . Introduction . In this project we focus on security people - as the world of IT becomes more widespread and increasingly complex, many security vulnerabilities arise which could potentially have an enormous impact on a company or worse case a whole country. There are a few guardians who dedicate their life to secure the IT infrastructure so we all can sleep peacefully. . We use the data from Twitter and build the network of security people based the friend concept of Twitter. With the network in hand, we perform a community calculation to find out whether these people are following into groups. And also understand what are they talking about by building the word cloud for each community. Finally, we detected the sentimentality of each community by analyzing the text of each person&#39;s biography that falls in the community. . Dataset . Twitter is the main source of our dataset. We used Twitter API combined with Tweepy library to download our dataset. . After crawling, cleaning, and formatting, 2 million rows of records have remained and gives us information like the name of the security people, the friends relationship with others which can be used to build the network later. . The overall size of the raw dataset is over 130 MB, which was extracted from over 3543 tweets. The 3543 tweets is just a start point of our dataset. By extracting the authors of the tweets and retrieve their friends, we get the main data of the network. As mentioned before, we also download all the biography of each people for the sentimentality analysis. . Network . The security people themselves will be the nodes in our network, and the concept of friends in Twitter will be the edges. . Our network is a graph to showcase who are friends with each other. . The graph below shows the structure of the security people network . # collapse-hide fig = plt.figure(figsize=(20, 10)) nx.draw_networkx_nodes(g, positions, node_size=node_sizes, alpha=0.4) nx.draw_networkx_edges(g, positions, edge_color=&quot;black&quot;, alpha=0.05, width=0.5) plt.title(&quot;Security People Network&quot;) plt.axis(&#39;off&#39;) fig.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-12-02T13:24:09.614828 image/svg+xml Matplotlib v3.3.0, https://matplotlib.org/ Statistics of the network . The network contains over 2000 nodes and over 18000 edges. The top ten nodes with highest degree are listed below . # collapse-hide print(&#39;Number of nodes&#39;, g.number_of_nodes()) print(&#39;Number of edges&#39;, g.number_of_edges()) . . Number of nodes 2050 Number of edges 18040 . # collapse-hide print(&quot;Top ten nodes sorted by degree&quot;) sorted(g.degree, key=lambda x: x[1], reverse=True)[:10] . . Top ten nodes sorted by degree . [(&#39;@HackingDave&#39;, 216), (&#39;@AlyssaM_InfoSec&#39;, 198), (&#39;@RayRedacted&#39;, 193), (&#39;@NicoleBeckwith&#39;, 178), (&#39;@DfirDiva&#39;, 170), (&#39;@sherrod_im&#39;, 161), (&#39;@cybergeekgirl&#39;, 161), (&#39;@gabsmashh&#39;, 160), (&#39;@LisaForteUK&#39;, 158), (&#39;@UK_Daniel_Card&#39;, 154)] . NLP . We want to explore how many security people there are and find out if they generally know each other. Find out if they can be split into some communities. Within these communities, we could try to use some Natural Language Processing to detect which community speaks most loudly and potentially see if there is a sentimentally difference. . Communities . We have 79 communities in our network and most of them contain less than 10 nodes. The graph below shows the count distribution of the communites. . # collapse-hide hist, bin_edges = np.histogram(list(len(com) for com in security_communities.values())) center = ((bin_edges[:-1] + bin_edges[1:]) / 2).round() fig = plt.figure(figsize=(20, 10)) plt.bar(center, hist) plt.title(&quot;Security community sizes&quot;) plt.ylabel(&quot;Count&quot;) plt.xlabel(&quot;Community size&quot;) plt.xticks(center) fig.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-12-02T13:24:13.796575 image/svg+xml Matplotlib v3.3.0, https://matplotlib.org/ In the later analysis, we mainly focus on the most largest 5 communities. . To better understand what are people in those communities talk about, we build a word cloud for each community. First, build a large document for each community by combining all the biographies of the people who locate in the community. Then tokenize the document and use the result to calculate TFs. Second, use the documents created from first step to calcualte IDF and finally use the result from the first two step to calculate TF-IDF. . The graph below shows the word clouds for each community. . From the graph we can observe that each community do focus on different field. For example, some foucs on social media, some focus on cyber security and some of them related with hacking. . # collapse-hide wordcloud = WordCloud( max_words=100, collocations=False, ) fig, axs = plt.subplots(nrows=len(tfidfs), ncols=1, figsize=(20,20)) for i, tfidf in enumerate(tfidfs): wordcloud.generate_from_frequencies(tfidf) axs[i].set_title(f&quot;Community {i+1}&quot;) axs[i].imshow(wordcloud, interpolation=&quot;bilinear&quot;) axs[i].axis(&quot;off&quot;) fig.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-12-02T13:24:18.300630 image/svg+xml Matplotlib v3.3.0, https://matplotlib.org/ Sentimentality . The other aspect we want to explore is the sentimentality of the communities. . First we collect tweets in each community and build a large string for each of them. Then tokenize those large strings and calcualte the sentimentality by getting the average value of all the tokens. . The list below shows the sentimentality value for each community, from the result we can see that the security people among different communities are generally in a similar neutral mood. . # collapse-hide def compute_average_sentiment(tokens): &quot;&quot;&quot;compute_average_sentiment returns the average sentiment value of the tokens. Each token in tokens must be in lowercase. &quot;&quot;&quot; sentiment = 0.0 if not len(tokens): return sentiment avg = np.nan_to_num(words_of_happiness[words_of_happiness[&quot;word&quot;].isin(tokens)][&quot;happiness_average&quot;].mean()) return avg communities = {i: set(members) for i, members in enumerate(top_5_largest_communites)} text_of_communities = collections.defaultdict(str) with open(&quot;sentiment_tweets.csv&quot;, newline=&quot;&quot;) as f: csv_reader = csv.DictReader(f) for row in csv_reader: for i, members in communities.items(): if row[&quot;screen_name&quot;] in members: text_of_communities[i] += f&quot; {row[&#39;tweets&#39;]}&quot; sentiment_of_communities = {k: compute_average_sentiment(bag_of_words(v)) for k, v in text_of_communities.items()} for com, sentiment in sentiment_of_communities.items(): print(f&quot;Community {com} have a sentiment value of {sentiment}&quot;) . . Community 3 have a sentiment value of 5.514023823358513 Community 1 have a sentiment value of 5.4363636363636365 Community 4 have a sentiment value of 5.458832378223495 Community 0 have a sentiment value of 5.455909920876445 Community 2 have a sentiment value of 5.5166643454039 . Conclusion . In this project, we build a network that represents the relationship of security people. . By buiding and exploring the communities of the network, we find out that the security people are generally fall into different groups that focus on diferent topics. . Finally, the sentimentality analysis shows that security people are commonly have similar mood no matter what community they belong to. .",
            "url": "https://narcissist1.github.io/02806-final-project/data_analysis/visualization/network/2020/12/02/Social-Graph-Project.html",
            "relUrl": "/data_analysis/visualization/network/2020/12/02/Social-Graph-Project.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "A mini introduction about cognitive services API.",
            "content": "Setup . The below image shows the architecture of concepts in Azure’s face recognition service. . . . Identify . .",
            "url": "https://narcissist1.github.io/02806-final-project/face%20recoginition/2020/07/14/Face-Recognition-API-Demo.html",
            "relUrl": "/face%20recoginition/2020/07/14/Face-Recognition-API-Demo.html",
            "date": " • Jul 14, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "02806 Final project",
            "content": ". Important: This page is generated from a Jupyter notebook, some of the code are hid under the hood, some of them can be shown by clicking the button Show Code. If you want to visit the complete notebook, please click the View On Github button above. . Introduction . Undoubtedly the recent appearrance and expansion of COVID-19 virus has affected the lives of billions of people worldwide in many aspects. Goverments have been under constant challenge to reduce social interaction in order to mitigate the possibilities of virus transmission. Therefore, they have introduced hard measurements to face this severe situation which have significant impact to every body&#39;s live. . Economy was one of the major areas that affected from those measurements. The work culture had to change to meet the derivative of the goverments, which led companies to move faster towards digitilisation. As a result companies that weren&#39;t eager in such changes to face important financial issues forcing them in many cases to reduce their human resources. For other companies such travelling agencies or companies in hospitalitty sector, the hit was even harder since they rely their profits entirely on the people&#39;s need for entertainment, social exploration etc.. Therefore, they have completely or partially shut down their operation leading many people in unemployment. The former also lead to goods surplus since demand from restaurants, hotels etc. has been reduced. Thus, a possible drop in prices as we go deeper in crisis is unavoidable. . The above constitutes some common observations and may look discouranging and demotivating facts. However, we can not conclude how big this impact is in each country&#39;s overall economy without a more in depth investigation of what other sectors have been impacted by COVID-19. . Upon that, we came to the desicion to analyse data from macroeconomic point of view in order to get a more clear understanding of how the virus has affected our economy. We will start the study by presenting a statistical analysis of how the situation with regards to COVID-19 looks like in the countries around the globe and we will narrow the analysis to the most impacted ones. Then we will include financial data to explore whether there is a significant impact of the virus in the economy of those countries. . In order to carry out the analysis we will use data for COVID-19 from github gist which they are updated every day. In that way we will have overview daily on the situation about the expansion of the virus. The financial data derived from IMF, OECD and other sources which can be found at the end of the page. We believe these datasets contains all the information needed to obtain the required outcome about the fincanial situation of the countries under consideration. . To sum up, from this study we aim to provide a conclusion about the economic consequences due to COVID-19. Through interactive and annotated graphs we want to give to the intendent audience all the information needed in order to understand the impact of COVID-19 in economy in a simple and concine manner. . Data analysis and visualization . We will start our analysis by illustrating the current situation of COVID-19 in a world map. The map has colored according to confirmed cases and summary of the rest of cases (e.g. Deaths, Recovered) can be seen by pointing on the country of interest. . Then we will continue by introducing the data about COVID-19 and later on in the study will go deeper in the economic data. . # collapse-hide # data preperation, combine refrence dataset to virus dataset to obtain area code for map plot refrence = refrence.rename(columns={&#39;Country_Region&#39;: &#39;Country/Region&#39;}) most_recent_data = world_data[world_data[&#39;Date&#39;] == world_data[&#39;Date&#39;].max()] most_recent_data = most_recent_data[[&#39;Date&#39;, &#39;Country/Region&#39;, &#39;Confirmed&#39;,&#39;Recovered&#39;,&#39;Deaths&#39;]] grouped = most_recent_data.groupby(&#39;Country/Region&#39;).sum() result = grouped.join(refrence.set_index(&#39;Combined_Key&#39;), on=&#39;Country/Region&#39;) result = result.fillna(value=0) result[&#39;code3&#39;] = result[&#39;code3&#39;].astype(int) # confirm map confirmMap = alt.Chart(alt.topo_feature(data.world_110m.url, &#39;countries&#39;), title=&#39;COVID-19 Confirm Overview&#39;).mark_geoshape( stroke=&#39;#aaa&#39;, strokeWidth=0.25 ).transform_lookup( lookup=&#39;id&#39;, from_=alt.LookupData(data=result, key=&#39;code3&#39;, fields=[&#39;Country/Region&#39;,&#39;Confirmed&#39;,&#39;Deaths&#39;,&#39;Recovered&#39;]) ).encode( alt.Color(&#39;Confirmed:Q&#39;, scale=alt.Scale(domain=[0, result.Confirmed.max()/10], clamp=True), legend=alt.Legend(format=&#39;&#39;)), tooltip = [(&#39;Country/Region:O&#39;),(&#39;Confirmed:Q&#39;),(&#39;Deaths:Q&#39;),(&#39;Recovered:Q&#39;)] ).project( type=&#39;equirectangular&#39; ).properties( width=900, height=500 ).configure_view( stroke=None ) confirmMap . . COVID-19 analysis . In this section, we will dive more into COVID-19 data to present the current situation of virus by illustrating the numbers of confirmed, recovered and death cases. Then with help of static and interactive represenations of those numbers we will try to understand the distribution as well as the death, infection and recovery rates of COVID-19. . In the following table is shown a sample of the data regarding COVID-19. This initial dataset contains columns with the countries, confirmed and recovered cases as well as overall deaths per country and corresponding date. . Date Country Confirmed Recovered Deaths . 21427 2020-05-14 | West Bank and Gaza | 375 | 310 | 2 | . 21428 2020-05-14 | Western Sahara | 6 | 6 | 0 | . 21429 2020-05-14 | Yemen | 85 | 1 | 12 | . 21430 2020-05-14 | Zambia | 654 | 124 | 7 | . 21431 2020-05-14 | Zimbabwe | 37 | 13 | 4 | . Exploration analysis . In this section we will perfrom a basic statistical analysis of the data in order to identify how the data are distibuted among the columns and to detect any important patterns that might be usefull in the further on analysis. . First, we will start by illustating the descriptive statistics of our dataset. In this way we can summarize the central tendency, dispersion and shape of our dataset&#39;s distribution. . In the table below it can be observed the great differences in the max values among the cases. The standard deviation is quite high in all the presented cases which means that our data is spread out. We can se also that the mean are very different as well. The overall average deaths across the countries is significantly lower that the confirmed and recovered cases. Meaning that the average death rate of the virus is 6.65 % and the average recovery rate is 28.35%. However, there are countries that have been impacted more than others and thus these rates are not equally distibuted among them. . Confirmed Recovered Deaths . count 2.143200e+04 | 21432.000000 | 21432.000000 | . mean 5.975546e+03 | 1762.100224 | 397.635545 | . std 4.615016e+04 | 11160.301452 | 3194.659394 | . min 0.000000e+00 | 0.000000 | 0.000000 | . 25% 0.000000e+00 | 0.000000 | 0.000000 | . 50% 1.100000e+01 | 0.000000 | 0.000000 | . 75% 4.610000e+02 | 54.000000 | 8.000000 | . max 1.417774e+06 | 246414.000000 | 85898.000000 | . The figure below illustrates the confirmed cases per country, in total 187 countries are shown. We have set a threshold of 100000 confirmed cases (red line in the graph). Countries with more than 100000 cases are shown in red bars. Countries with confirmed cases between 10000-100000 are shown in orange bars while the rest with cases below shown in blue bars (less than 10000 cases). . It can clearly observed that the threshold of 100000 cases has been exceeded by Brazil, Italy, Spain, Iran, UK, USA, France, Germany, Russia and Turkey. Four of those countries (Spain, USA,Italy, UK) have crossed the threshold of 200000 incidents, while the cases in USA have reached the extreme record of approximatelly 1400000 cases. The above mentioned countries gather the 72.37% (by the day the report was written) of total confirmed cases worldwide. The 22,87% of the cases gathered in countries with confirmed cases in between 10000 and 100000 while the remaining 4.76% is recorded from the rest of the countries. . Another interesting observation is that Italy, USA, Germany, France and United Kingdom (countries that have been hit hardly by COVID-19) are among the seven largest IMF- advanced economies in the world. Meaning that potential impact in their economy due to virus could directly affect the global economy. . #collapse-hide # mutiple color support, key is the plot color, value is the confirmed cases range colorDict = { &#39;blue&#39;: (0, 10000), &#39;orange&#39;: (10001, 100000), &#39;red&#39;: (100001, 100000000) } def addColorType(df, colorDict): # assign default color df[&#39;Color&#39;] = 3 for key, val in colorDict.items(): df.loc[(df[&#39;Confirmed&#39;] &gt; val[0]) &amp; (df[&#39;Confirmed&#39;] &lt;= val[1]), [&#39;Color&#39;]] = key Threshold = pd.DataFrame({&#39;Threshold&#39;:[100000]}) # continuous coloring domain = [10000, 100000, 100000000] range_ = [&#39;blue&#39;, &#39;red&#39;, &#39;green&#39;] #summary of all the countries # get the last day&#39;s data, The conifrmed cases is accumulated, so the last day&#39;s data includes all confirmed cases so far plotData = full_clean_data.loc[full_clean_data.Date == full_clean_data.Date.max()] addColorType(plotData, colorDict) summary = alt.Chart(plotData).mark_bar().encode( x=alt.X(&#39;Country:O&#39;,sort=&#39;-y&#39;), y=alt.Y(&quot;Confirmed:Q&quot;), tooltip = [alt.Tooltip(&#39;Country&#39;), alt.Tooltip(&#39;Confirmed&#39;)], # The highlight will be set on the result of a conditional statement # color=alt.Color(&#39;Confirmed&#39;, scale=alt.Scale(domain=domain, range=range_)) color=alt.Color(&#39;Color&#39;, legend=None) ).properties(width=3000,height=400) rule = alt.Chart(Threshold).mark_rule(color=&#39;red&#39;).encode( y=alt.Y(&#39;Threshold:Q&#39;),tooltip = [alt.Tooltip(&#39;Threshold&#39;)] ) (summary+rule) . . In the figures belows is illustrated the maximum values of the cases for the corresponding countries (that have exceeded the threshold of 100000 confirmed cases) in order to identify which countries have recorded the highest numbers of confirmed, recovered and death incidents due to COVID-19. From a first sight we can observe that the cases are not proportional with each other. For example the countries with the most confirmed cases they don&#39;t necessarily record the most deaths or recovered cases. . Also we observe significant fluctuations on how the cases are distibuted among the countries. For instance, there is no consistency on how the cases increased in each country. This is of course rational as the number of deaths, recovered etc. highly depends on factors such the health care system of each country, the population age and so on. Factors that are beyond the scope of this study. . # collapse-hide group = full_clean_data.groupby(&#39;Country&#39;)[&#39;Deaths&#39;,&#39;Confirmed&#39;,&#39;Recovered&#39;].max().sort_values(by=[&#39;Deaths&#39;,&#39;Confirmed&#39;,&#39;Recovered&#39;]) group = pd.DataFrame(group) group = group.reset_index() # keep only the countries with more than 10000 deaths new_group = group.query(&quot;Confirmed &gt;= 100000&quot;) countries = list(new_group.Country.unique()) #define colors red = alt.value(&#39;#f54242&#39;) green = alt.value(&#39;#137E2A&#39;) black = alt.value(&#39;#050404&#39;) #presenting the confirmed cases per country bars = alt.Chart(new_group).mark_bar(size=5).encode( x=&#39;Confirmed:Q&#39;, y=alt.Y(&quot;Country:O&quot;, sort=&#39;-x&#39;),color = red ) text = bars.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;Confirmed:Q&#39;,color =black ) bars2 = alt.Chart(new_group).mark_bar(size=5).encode( x=&#39;Recovered:Q&#39;, y=alt.Y(&quot;Country:O&quot;, sort=&#39;-x&#39;),color=green ) text2 = bars2.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;Recovered:Q&#39;,color=black ) bars3 = alt.Chart(new_group).mark_bar(size=5).encode( x=&#39;Deaths:Q&#39;, y=alt.Y(&quot;Country:O&quot;, sort=&#39;-x&#39;),color=black ) text3 = bars3.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;Deaths:Q&#39;,color=black ) laydermap = (bars + text).properties(width= 250,height=300)|(bars2+text2).properties(width= 250,height=300)|(bars3+text3).properties(width=250,height=300) laydermap.configure_axis(grid=False).configure_view(strokeWidth=0) . . A calculation about the overall deaths and recovered cases yields that the 10 countries under consideration accumulate the 79.95% and 66.51% of the deaths and recovered cases respectively. While countries which record cases between 10 and 100 thousand gather the 17.78% and 26.98% of the deaths and recovered cases accordingly. The rest 2.26% of deaths and 6.51% of recovered cases is aggregated in countries with less than 10 thousand incidents. . It can clearly be concluded that the countries with more total incidents have the more total deaths as well. Something that isn&#39;t valid when we focus on countries individually as we saw above. We can clearly see that even though many countries have been hit by COVID-19 solely 10 have affected significantly while the rest have suffered by a moderate to low impact in terms of total deaths. . Data analysis of the major countries . Following the findings from the preliminary exploration analysis we focus on the 10 countries that have been affected the most by COVID-19 virus. . In order to extract more information as possible from the dataset it is necessary to combine several datasets. By doing so, we include columns referring to daily new cases, new deaths and new recovered cases. This new data refer to how much the corresponding cases changed compared to the day before. . An investigation for missing values and treatment of those it is also a requirement to bring the dataset in form ready for analysis. In the present study the missing values were filled with zeros. It considered the best way to treat such a values because if for example the missing values were filled with the mean, mode or median could lead to false interpration of the results. . In the following tables it is shown first, a sample of the final dataset about COVID-19 after the preprossesing, followed by the table that contains the descriptive stastics of the dataset. . # collapse-show # data processing to create Active, New cases, New deaths, New recovered full_clean_data[&#39;Active&#39;] = full_clean_data[&#39;Confirmed&#39;] - full_clean_data[&#39;Recovered&#39;] - full_clean_data[&#39;Deaths&#39;] selected_data = full_clean_data[full_clean_data[&#39;Country&#39;].isin(countries)] for i in selected_data.index: date = selected_data.loc[i, &#39;Date&#39;] country = selected_data.loc[i, &#39;Country&#39;] date = datetime.strptime(date, &#39;%Y-%m-%d&#39;) yesterday = datetime.strftime(date - timedelta(1), &#39;%Y-%m-%d&#39;) yesterdayData = selected_data.loc[(selected_data.Date == yesterday) &amp; (selected_data.Country == country)] if len(yesterdayData) &lt;= 0: selected_data.loc[i, &#39;New cases&#39;] = 0 selected_data.loc[i, &#39;New deaths&#39;] = 0 selected_data.loc[i, &#39;New recovered&#39;] = 0 continue yesterdayData = yesterdayData.iloc[0] selected_data.loc[i, &#39;New cases&#39;] = selected_data.loc[i, &#39;Confirmed&#39;] - yesterdayData.Confirmed selected_data.loc[i, &#39;New deaths&#39;] = selected_data.loc[i, &#39;Deaths&#39;] - yesterdayData.Deaths selected_data.loc[i, &#39;New recovered&#39;] = selected_data.loc[i, &#39;Recovered&#39;] - yesterdayData.Recovered selected_data = selected_data.fillna(value=0) selected_data[&#39;New cases&#39;] = selected_data[&#39;New cases&#39;].astype(int) selected_data[&#39;New deaths&#39;] = selected_data[&#39;New deaths&#39;].astype(int) selected_data[&#39;New recovered&#39;] = selected_data[&#39;New recovered&#39;].astype(int) . . Date Country Confirmed Recovered Deaths Active New cases New deaths New recovered . 21384 2020-05-14 | Russia | 252245 | 53530 | 2305 | 196410 | 9974 | 93 | 5527 | . 21402 2020-05-14 | Spain | 229540 | 143374 | 27321 | 58845 | 849 | 217 | 2551 | . 21417 2020-05-14 | Turkey | 144749 | 104030 | 4007 | 36712 | 1635 | 55 | 2315 | . 21418 2020-05-14 | US | 1417774 | 246414 | 85898 | 1085462 | 27368 | 1779 | 2984 | . 21422 2020-05-14 | United Kingdom | 234440 | 1043 | 33693 | 199704 | 3455 | 429 | 11 | . In the table below we can see the basic statistics for the 10 under study countries. By looking the new data added seems to be less spread out than the already existed ones. Additionally, we can see that the average new deaths per day are about 204 while the new confirmed (new cases) and recovered record an average of 2713 and 848 new cases per day respectively. We can also see that the maximum values of the new data are quite high for every day cases. . Confirmed Recovered Deaths Active New cases New deaths New recovered . count 1.132000e+03 | 1132.000000 | 1132.000000 | 1.132000e+03 | 1132.000000 | 1132.000000 | 1132.000000 | . mean 7.856263e+04 | 20190.606890 | 5875.987633 | 5.249603e+04 | 2790.848057 | 209.314488 | 915.359541 | . std 1.788074e+05 | 38835.693405 | 12221.566700 | 1.415041e+05 | 5818.165746 | 415.157452 | 2001.502784 | . min 0.000000e+00 | 0.000000 | 0.000000 | 0.000000e+00 | 0.000000 | 0.000000 | 0.000000 | . 25% 5.750000e+00 | 0.000000 | 0.000000 | 4.000000e+00 | 0.000000 | 0.000000 | 0.000000 | . 50% 4.634000e+03 | 105.000000 | 91.000000 | 4.327500e+03 | 592.500000 | 16.000000 | 1.000000 | . 75% 1.042815e+05 | 22491.750000 | 5392.750000 | 5.494175e+04 | 3117.500000 | 201.000000 | 1317.250000 | . max 1.417774e+06 | 246414.000000 | 85898.000000 | 1.085462e+06 | 36188.000000 | 2612.000000 | 33227.000000 | . Below it is illustrated how the daily new cases are spread out across time. . It is observed that Italy it was the first country (among the 10 tested countries) that COVID-19 incidents appeared followed by Iran, France, Germany and Spain while the rest of the countries are following shortly after. Overall from 15th of February - 15th of March the virus was present in all the countries. . It seems that in Russia and Brazil the number of daily cases is following an increasing fashion. Also in Iran appears that the daily new cases have started increasing slightly from 1st of May and after a period of reduction in incedents. Indicating that the virus can potentially reoccur if mismanagement of the crisis (from goverments,citizens etc.) take place. Although this fact requires further investigation in order to find the reasons behind it. . On the other hand, in Italy, Spain, Germany and less in Turkey the virus appears to record a decreasing trend since late April. The same in France, however, in some days seems that the cases show an increase and then start decreasing again. Significant fluctuations though, considering that one day 3000 cases recorded while the next merely 750 (look between 29th of April and 1st of May). . In the UK the virus daily new cases have remained steady in high levels since the 5th of April, while in the USA we observe that the daily cases showed a rapid increase in the first days of the virus and have remained in significant high levels ever since. . Also this steady condition seems that it has lasted more in the UK and USA than the rest of the countries that suffered first from the virus (e.g. Italy, Spain,France, Germany). . In general, it seems that in countries like the USA, UK, Russia and Brazil the virus hasn&#39;t reached its peak yet while in the rest of the countries (apart from Iran which records an increase again in daily cases) the daily new cases seems to fade out at the moment. . . Tip: By creating a rectangular with the mouse in the upper graph you can see the cases over time, while in plot underneath is shown cumulated new cases. . # collapse-hide # plot interval = alt.selection_interval() circle = alt.Chart(tmp, title=&#39;Spread and New Cases Over Time&#39;).transform_filter( alt.datum.Country).mark_circle().encode( x=&#39;monthdate(Date):O&#39;, y=&#39;Country&#39;, color=alt.condition(interval, &#39;Country&#39;, alt.value(&#39;lightgray&#39;)), size=alt.Size(&#39;New cases:Q&#39;, scale=alt.Scale(range=[0, 3000]), legend=alt.Legend(title=&#39;Daily new cases&#39;) ) ).properties( width=1000, height=400, selection=interval ) bars = alt.Chart(tmp).mark_bar().encode( y=&#39;Country&#39;, color=&#39;Country&#39;, x=&#39;sum(New cases):Q&#39; ).properties( width=1000 ).transform_filter( interval ) circle &amp; bars . . In the graphs below is illustrated the average daily cases across the countries. We can obsereve, that the recovered cases are significantly higher from the deaths apart from the UK which the opposite happens. As discussed previously in the study the countries with the more confirmed cases they don&#39;t necessarily show the most deaths and/or recovered cases. . # collapse-hide group2 = selected_data.groupby(&#39;Country&#39;)[&#39;New deaths&#39;,&#39;New cases&#39;,&#39;New recovered&#39;].mean().sort_values(by=[&#39;New deaths&#39;,&#39;New cases&#39;,&#39;New recovered&#39;]) group2 = pd.DataFrame(group2.round()) group2 = group2.reset_index() # # keep only the countries with more than 100000 confirmed new_group2 = group2 #define colors red = alt.value(&#39;#f54242&#39;) green = alt.value(&#39;#137E2A&#39;) black = alt.value(&#39;#050404&#39;) #presenting the confirmed cases per country bars = alt.Chart(new_group2).mark_bar(size=5).encode( x=&#39;New cases:Q&#39;, y=alt.Y(&quot;Country:O&quot;, sort=&#39;-x&#39;),color = red ) text = bars.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;New cases:Q&#39;,color =black ) bars2 = alt.Chart(new_group2).mark_bar(size=5).encode( x=&#39;New recovered:Q&#39;, y=alt.Y(&quot;Country:O&quot;, sort=&#39;-x&#39;),color=green ) text2 = bars2.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;New recovered:Q&#39;,color=black ) bars3 = alt.Chart(new_group2).mark_bar(size=5).encode( x=&#39;New deaths:Q&#39;, y=alt.Y(&quot;Country:O&quot;, sort=&#39;-x&#39;),color=black ) text3 = bars3.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;New deaths:Q&#39;,color=black ) laydermap = (bars + text).properties(width= 250,height=300)|(bars2+text2).properties(width= 250,height=300)|(bars3+text3).properties(width=250,height=300) laydermap.configure_axis(grid=False).configure_view(strokeWidth=0) . . This disrepancy among the cases across the countries means that the countries have different death and recovery rates as well as infection rates. In the graph below the aforementioned rates are shown for each country individually for the total amount of each case. . #collapse-hide #data preprocessing #death rate selected_data[&#39;DeathRate&#39;] = selected_data[&#39;Deaths&#39;]/selected_data[&#39;Confirmed&#39;] * 100 selected_data = selected_data.fillna(value=0) #recovery rate selected_data[&#39;RecoveryRate&#39;] = selected_data[&#39;Recovered&#39;]/selected_data[&#39;Confirmed&#39;]*100 selected_data = selected_data.fillna(value=0) #infection rate population = {&#39;Brazil&#39;:212559417, &#39;Germany&#39;:82002000, &#39;Russia&#39;:144005000, &#39;Turkey&#39;:82000000, &#39;France&#39;:65273511, &#39;Italy&#39;:60461826, &#39;Spain&#39;:46754775, &#39;US&#39;:331002651, &#39;United Kingdom&#39;:67886011, &#39;Iran&#39;:83992949} for i in selected_data[&#39;Country&#39;]: for key,value in population.items(): if i == key: selected_data[&#39;InfectionRate&#39;] = selected_data[&#39;Confirmed&#39;]/value * 100 # A dropdown filter countries = list(selected_data.Country.unique()) country_dropdown = alt.binding_select(options=countries) country_select = alt.selection_single(fields=[&#39;Country&#39;], bind=country_dropdown, name=&quot;Select&quot;,init={&#39;Country&#39;: &#39;US&#39;}) #plot infection rate filter_infectionrates = alt.Chart(selected_data, width=300, height=300, title=&#39;Infection Rate&#39;).mark_line().encode( alt.X(&#39;Date:T&#39;), alt.Y(&#39;InfectionRate:Q&#39;, title= &#39;Infection Rate %&#39;), color=&#39;Country&#39;, tooltip = [alt.Tooltip(&#39;InfectionRate:Q&#39;)] ).add_selection(country_select).transform_filter(country_select) # plot death rate filter_deathrate = alt.Chart(selected_data, width=300, height=300, title=&#39;Death Rate&#39;).mark_line().encode( alt.X(&#39;Date:T&#39;), alt.Y(&#39;DeathRate:Q&#39;, title= &#39;Death Rate %&#39;), color=&#39;Country&#39;, tooltip = [alt.Tooltip(&#39;DeathRate:Q&#39;)] ).add_selection(country_select).transform_filter(country_select) # plot recovery rate filter_recovery = alt.Chart(selected_data, width=300, height=300, title=&#39;Recovery Rate&#39;).mark_line().encode( alt.X(&#39;Date:T&#39;), alt.Y(&#39;RecoveryRate:Q&#39;, title= &#39;Recovery Rate %&#39;), color=&#39;Country&#39;, tooltip = [alt.Tooltip(&#39;RecoveryRate:Q&#39;)] ).add_selection(country_select).transform_filter(country_select) (filter_infectionrates | filter_deathrate | filter_recovery) . . Exploring, initially the infection rates for each country it can be observed infection rates have recorded an increasing trend since the firt day the virus appeared for all the countries. More precicely by the day the report was written all the countries apart from the USA recond infection rates in range between 0.16%-0.30%. Relatively low percentages compare to their populations which ranges between 40 million (Spain) to 200 million people(Brazil). On the other hand in the USA the infection rate records an increment of 2%. Significantly higher compare to the rest of the countries. . Moving forward to death rates, an increasing trend is still observed, however more fluctuations are recorded. For example, in case of Iran there is a spike around 20-23 of February where a death rate of 100% is recorded. This is quite unsual, although the confirmed incidents at that time were quite few thus, this fluctuation might correspond to 1 or 2 deaths out of 1 or 2 incidents. Same anomalies observed also in case of France where about the same period of time a high increase in death rate is recorded followed by a rapid decrease until it started to increase again in a more steady trend. Similarly for the USA. The highest death rates are recorded in France, Italy and Spain with 15%,14% and 12% respectively. . At last, the recovery rates varies a lot among the countries. The highest recovery rate of 82% is recorded in Germany while the lower in the United Kingdom which is almost 0%. As in the death rates few anomalies observed in the first days of the virus where some countries record recovery rates of 100%. In Russia this seemed that it lasted for almost a month while in the same period of time recorded 0% death rate. After the 9th of March the recovery rate droped to 10% for Russia and death rates increased from 0% to 0.5%. This could be due to falsesly recorded data. However, greater investigation needed to make robust conclusions about it which is beyond the scope of the study. . Reaching the end of this section we would like to compress the outcome of the analysis by illustrating the relationship among the cases for each country throughout the period of COVID-19 impact. The graph below depicts the key points of the COVID-19 analysis and illustrates the confirmed cases per deaths per day since 22/01/2020 while the magnitude of the recovered cases is shown by the size of the bubbles. . . Tip: The situation changing over time can be seen by drag the bar below the bubble plot . # collapse-hide # data processing start_date = datetime.strptime(&#39;2020-01-22&#39;, &#39;%Y-%m-%d&#39;) for index, row in selected_data.iterrows(): date = datetime.strptime(row[&#39;Date&#39;], &#39;%Y-%m-%d&#39;) selected_data.loc[index, &#39;Day&#39;] = (date - start_date).days selected_data[&#39;Day&#39;] = selected_data[&#39;Day&#39;].astype(int) # plot select_date = alt.selection_single( name=&#39;select&#39;, fields=[&#39;Day&#39;], init={&#39;Day&#39;: 0}, bind=alt.binding_range(min=0, max=selected_data.Day.max(), step=1) ) alt.Chart(selected_data, title=&#39;COVID-19 Spread Over Time&#39;).mark_point(filled=True).encode( alt.X(&#39;Confirmed&#39;, scale=alt.Scale(zero=False)), alt.Y(&#39;Deaths&#39;, scale=alt.Scale(zero=False)), alt.Size(&#39;Recovered&#39;,scale=alt.Scale(zero=False)), alt.Color(&#39;Country&#39;), alt.Order(&#39;Confirmed&#39;, sort=&#39;descending&#39;), tooltip = [alt.Tooltip(&#39;Country&#39;), alt.Tooltip(&#39;Confirmed&#39;), alt.Tooltip(&#39;Deaths&#39;), alt.Tooltip(&#39;Recovered&#39;) ], ).properties( width=700, height=400 ).add_selection(select_date).transform_filter(select_date) . . By scrolling the slide on the bottom of the graph a man can observe the overall impact of COVID-19 per day as well as how the virus has impacted the countries throughout the entire period which numbers 113 days so far ( by the day the report was written) . . Note: The UK is hard to see due to the very low score of recovered cases . We observe that the deaths and recovered cases have been increasing as long the confirmed cases increasing. Although the rates differ among the countries as we show in the graphs above. We can see that around day 113 the countries are distinguished in three clusters. The one is the USA itself by accumulating the highest numbers of all the cases. The second cluster constitues of Spain, Italy, France and the UK due to the higher number of deaths they have (approximate average 30000) compared to the rest of the countries(third cluster) which record an approximate of 8000 - 10000 deaths. . After diving into the details on how the incidents of COVID-19 have been formed so far, we moving forward to the study to investigate the economic consuquences of the virus on the under study countries. As mentioned before, 5 of those countries constitue the most advanced economies of the world. Thus, a potential hit in their economies due to COVID-19 could have significant impact on other countries&#39; economies as well. . Economic Analysis . In this section we will attempt to perform an economic analysis from a macroeconimic point of view and in relation to the COVID-19 analysis above. We will try to come up with potential coclusions on how the spread of the virus has affected the global economy . . Note: Data about economic situation in Iran wasn&#8217;t available thus, Iran is not included in this part of the study . We have divided the analysis in three parts. In the first one we look at the stock market of each country and analyse the major indices of those as well as some of their primary sectors&#39; performance. The second part focues on a more macroeconomic approach where we focus on countries&#39; GDP, unemployment rates and inflation. The third part is a brief investigation on countries&#39; imports/exports. . Stock Market . In the graph below the prices of stocks in major indices and primary sector are illustrated. The graph shows how the prices have been formed from 01/04/2019-30/04/2020. . . Note: The stocks data don&#8217;t derive from an open API thus it is difficult to update them daily. Thus we decided to show one year period. . A short reminder that the virus started spreading in the focus countries around 22/01/2020 and reaching its peak between March - April for the most of the countries. . #collapse-hide # preprocessing data # France stockCAC40[&#39;Symbol&#39;]=&#39;CAC 40&#39; CACbasic[&#39;Symbol&#39;] = &#39;CAC Basic Materials&#39; CACconsumer[&#39;Symbol&#39;] = &#39;CAC Consumer Goods&#39; CACservice[&#39;Symbol&#39;] = &#39;CAC Consumer Services&#39; CACtech[&#39;Symbol&#39;] = &#39;CAC Technology&#39; CAChealth[&#39;Symbol&#39;] = &#39;CAC Health Care&#39; cacall[&#39;Symbol&#39;] = &#39;France All Shares&#39; stockFRA = pd.concat([stockCAC40,CACbasic,CACconsumer,CACservice,CACtech, CAChealth,cacall],sort = True) stockFRA[&#39;Date&#39;] = pd.to_datetime(stockFRA.Date) stockFRA = stockFRA.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockFRA[&#39;Price&#39;] = stockFRA[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockFRA[&#39;Price&#39;] = stockFRA[&#39;Price&#39;].astype(float) # Italy stockMIB[&#39;Symbol&#39;]=&#39;MIB&#39; utilities[&#39;Symbol&#39;] = &#39;FTSE Utilities&#39; Technology[&#39;Symbol&#39;] = &#39;FTSE Technology&#39; O_G[&#39;Symbol&#39;] = &#39;FTSE Oil &amp; Gas&#39; Travel[&#39;Symbol&#39;] = &#39;FTSE Travel &amp; Leisure&#39; industrials[&#39;Symbol&#39;] = &#39;FTSE Industrials&#39; financials[&#39;Symbol&#39;] = &#39;FTSE Financials&#39; health[&#39;Symbol&#39;] = &#39;FTSE Health Care&#39; chemicals[&#39;Symbol&#39;] = &#39;FTSE Chemicals&#39; allsharesitalia[&#39;Symbol&#39;] = &#39;Italy All Shares&#39; stockITA = pd.concat([stockMIB,utilities,Technology,O_G,Travel, industrials,financials,health,chemicals,allsharesitalia],sort = True) stockITA[&#39;Date&#39;] = pd.to_datetime(stockITA.Date) stockITA = stockITA.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockITA[&#39;Price&#39;] = stockITA[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockITA[&#39;Price&#39;] = stockITA[&#39;Price&#39;].astype(float) # Spain ibex[&#39;Symbol&#39;]=&#39;IBEX 35&#39; materialssp[&#39;Symbol&#39;] = &#39;Basic Materials Industry and Construction&#39; consumersp[&#39;Symbol&#39;] = &#39;Consumer Goods&#39; servicesp[&#39;Symbol&#39;] = &#39;Services&#39; petrolsp[&#39;Symbol&#39;] = &#39;Petrol and Power&#39; spainall[&#39;Symbol&#39;] = &#39;Spain All Shares&#39; stockSP = pd.concat([ibex,materialssp,consumersp,servicesp,petrolsp,spainall],sort = True) stockSP[&#39;Date&#39;] = pd.to_datetime(stockSP.Date) stockSP = stockSP.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockSP[&#39;Price&#39;] = stockSP[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockSP[&#39;Price&#39;] = stockSP[&#39;Price&#39;].astype(float) # UK ftse100[&#39;Symbol&#39;]=&#39;FTSE 100&#39; auto[&#39;Symbol&#39;] = &#39;Automobiles &amp; Parts&#39; forestry[&#39;Symbol&#39;] = &#39;Forestry &amp; Paper&#39; metals[&#39;Symbol&#39;] = &#39;Industrial Metals &amp; Mining&#39; telecom[&#39;Symbol&#39;] = &#39;Mobile Telecommunications&#39; realestate[&#39;Symbol&#39;] = &#39;Real Estate&#39; beverage[&#39;Symbol&#39;] = &#39;Beverages&#39; ukall[&#39;Symbol&#39;] = &#39;United Kingdom All Shares&#39; chemicalsuk[&#39;Symbol&#39;] = &#39;Chemicals&#39; construction[&#39;Symbol&#39;] = &#39;Construction &amp; Building Materials&#39; stockUK = pd.concat([ftse100,auto,forestry,metals,telecom,realestate,beverage,chemicalsuk,construction,ukall],sort = True) stockUK[&#39;Date&#39;] = pd.to_datetime(stockUK.Date) stockUK = stockUK.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockUK[&#39;Price&#39;] = stockUK[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockUK[&#39;Price&#39;] = stockUK[&#39;Price&#39;].astype(float) # Turkey bist[&#39;Symbol&#39;]=&#39;BIST 100&#39; basictu[&#39;Symbol&#39;] = &#39;Metals &amp; Mining&#39; chemtu[&#39;Symbol&#39;] = &#39;Chem Petrol Plastic&#39; electu[&#39;Symbol&#39;] = &#39;Electricity&#39; foodtu[&#39;Symbol&#39;] = &#39;Food &amp; Beverages&#39; industrialstu[&#39;Symbol&#39;] = &#39;Industrials&#39; financialstu[&#39;Symbol&#39;] = &#39;Financial&#39; ittu[&#39;Symbol&#39;] = &#39;Information Technology&#39; tourtu[&#39;Symbol&#39;] = &#39;Tourism&#39; stockTU = pd.concat([bist,basictu,chemtu,electu,foodtu,financialstu,industrialstu,ittu, tourtu],sort = True) stockTU[&#39;Date&#39;] = pd.to_datetime(stockTU.Date) stockTU = stockTU.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockTU[&#39;Price&#39;] = stockTU[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockTU[&#39;Price&#39;] = stockTU[&#39;Price&#39;].astype(float) # USA dow30[&#39;Symbol&#39;]=&#39;Dow 30&#39; SP[&#39;Symbol&#39;] =&#39;S&amp;P 500&#39; nasdaq[&#39;Symbol&#39;] =&#39;NASDAQ&#39; banksus[&#39;Symbol&#39;] = &#39;Banks&#39; financialsus[&#39;Symbol&#39;] = &#39;Financials&#39; industrialsus[&#39;Symbol&#39;] = &#39;Industrials&#39; insuranceus[&#39;Symbol&#39;] = &#39;Insurance&#39; computersus[&#39;Symbol&#39;] = &#39;Computers&#39; telecomus[&#39;Symbol&#39;] = &#39;Telecommunications&#39; transportationus[&#39;Symbol&#39;] = &#39;Transportation&#39; stockUS = pd.concat([dow30,SP, nasdaq,banksus,financialsus,industrialsus, insuranceus,computersus, telecomus,transportationus],sort = True) stockUS[&#39;Date&#39;] = pd.to_datetime(stockUS.Date) stockUS = stockUS.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockUS[&#39;Price&#39;] = stockUS[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockUS[&#39;Price&#39;] = stockUS[&#39;Price&#39;].astype(float) # Germany dax[&#39;Symbol&#39;]=&#39;DAX&#39; autogr[&#39;Symbol&#39;] = &#39;Automobile&#39; chemicalsgr[&#39;Symbol&#39;] = &#39;Chemicals&#39; constructiongr[&#39;Symbol&#39;] = &#39;Construction&#39; banksgr[&#39;Symbol&#39;] = &#39;Banks&#39; consumergr[&#39;Symbol&#39;] = &#39;Consumer&#39; financialsgr[&#39;Symbol&#39;] = &#39;Financial&#39; foodgr[&#39;Symbol&#39;] = &#39;Food &amp; Beverages&#39; industrialgr[&#39;Symbol&#39;] = &#39;Industrial&#39; stockGR = pd.concat([dax,autogr,chemicalsgr,constructiongr,banksgr,consumergr,financialsgr, foodgr,industrialgr],sort = True) stockGR[&#39;Date&#39;] = pd.to_datetime(stockGR.Date) stockGR = stockGR.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockGR[&#39;Price&#39;] = stockGR[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockGR[&#39;Price&#39;] = stockGR[&#39;Price&#39;].astype(float) # Russia moex[&#39;Symbol&#39;]=&#39;MOEX&#39; miningru[&#39;Symbol&#39;] = &#39;Metals &amp; Mining&#39; chemicalsru[&#39;Symbol&#39;] = &#39;Chemicals&#39; electricityru[&#39;Symbol&#39;] = &#39;Electricity&#39; oilru[&#39;Symbol&#39;] = &#39;Oil &amp; Gas&#39; transportru[&#39;Symbol&#39;] = &#39;Transport&#39; consumerru[&#39;Symbol&#39;] = &#39;Consumer&#39; financialsru[&#39;Symbol&#39;] = &#39;Financial&#39; teleru[&#39;Symbol&#39;] = &#39;Telecommunication&#39; stockRU = pd.concat([moex,miningru,chemicalsru,electricityru,oilru,transportru, consumerru,financialsru,teleru],sort = True) stockRU[&#39;Date&#39;] = pd.to_datetime(stockRU.Date) stockRU = stockRU.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockRU[&#39;Price&#39;] = stockRU[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockRU[&#39;Price&#39;] = stockRU[&#39;Price&#39;].astype(float) # Brazil bovespa[&#39;Symbol&#39;]=&#39;Bovespa&#39; basicbr[&#39;Symbol&#39;] = &#39;Basic Materials&#39; electricalbr[&#39;Symbol&#39;] = &#39;Electricity&#39; financialbr[&#39;Symbol&#39;] = &#39;Industrial&#39; industrialbr[&#39;Symbol&#39;] = &#39;Gas &amp; Water&#39; consumptionbr[&#39;Symbol&#39;] = &#39;Consumption&#39; healthbr[&#39;Symbol&#39;] = &#39;Health Care&#39; realestatebr[&#39;Symbol&#39;] = &#39;Real Estate Investment &amp; Services&#39; stockBR = pd.concat([bovespa,basicbr,electricalbr,industrialbr,consumptionbr,financialbr,healthbr, realestatebr],sort = True) stockBR[&#39;Date&#39;] = pd.to_datetime(stockBR.Date) stockBR = stockBR.sort_values(by=[&#39;Symbol&#39;,&#39;Date&#39;]) stockBR[&#39;Price&#39;] = stockBR[&#39;Price&#39;].str.replace(&#39;,&#39;,&#39;&#39;) stockBR[&#39;Price&#39;] = stockBR[&#39;Price&#39;].astype(float) # add country column stockFRA[&#39;Country&#39;]=&#39;France&#39; stockITA[&#39;Country&#39;]=&#39;Italy&#39; stockSP[&#39;Country&#39;]=&#39;Spain&#39; stockUK[&#39;Country&#39;]=&#39;UK&#39; stockUS[&#39;Country&#39;]=&#39;United States&#39; stockBR[&#39;Country&#39;]=&#39;Brazil&#39; stockGR[&#39;Country&#39;]=&#39;Germany&#39; stockRU[&#39;Country&#39;]=&#39;Russia&#39; stockTU[&#39;Country&#39;]=&#39;Turkey&#39; stocks = pd.concat([stockFRA,stockITA,stockSP,stockUK,stockUS, stockBR,stockGR,stockRU,stockTU],sort = True) #dropdown countries = list(stocks.Country.unique()) country_dropdown = alt.binding_select(options=countries) country_select = alt.selection_single(fields=[&#39;Country&#39;], bind=country_dropdown, name=&quot;Select&quot;, init={&#39;Country&#39;: &#39;United States&#39;}) line = alt.Chart(stocks, title=&#39;Major Index &amp; Primary Sectors Stocks Price (Major Countries)&#39;).mark_line(interpolate=&#39;basis&#39;,size=5).encode( x = &#39;Date&#39;, y = &#39;Price&#39;, color=&#39;Symbol&#39;, strokeDash=&#39;Symbol&#39;, tooltip = [alt.Tooltip(&#39;Symbol:N&#39;), alt.Tooltip(&#39;Price:Q&#39;)] ).properties(width=700, height=500).add_selection(country_select).transform_filter(country_select) line . . Across countries a common pattern that is observed is that almost all indices and primary sectors record a drop in their prices. . In France we observe significant drop in CAC40(Major index) from 6000 to 4000 units following by a slow increase of 2000 units from mid March until end of April. So it seems that French general economy starts slowly, to going back to normal after the strong hit in the beginning of March. This can also be observed from the increase trend of the primary sectors indices. . Italy was one of the countries that impacted first from COVID-19. We can see that the sectors that affected the most were the health care and technology. Although they have reached back to prior COVID-19 levels by the end of April. MIB (Italy&#39;s major index) records a drop of 5000 units without showing any signigicant increase thereafter. . In Spain we observe a high drop in its major index(IBEX 35) which depicts the strongest 35 spanish companies. It also seems that the major index price follows a steady course after its drop. Meaning that the major companies in Spain don&#39;t seem to overcome the crisis quickly. In regards to the rest of the sectors, the consumer good sectors has impacted the most while the rest of them have droped in a smaller scale. As we can see for the index &quot; Spain all shares&quot; the overall picture of the spanish economy doesn&#39;t look that has been affected in important levels. This is contorversial towards the IBEX 35 (major index) but the &quot;Spain all shares&quot;depicts shares from all the companies in Spain and not only the 35 stongest ones. Thus, it gives a better general overview of the economy. Further investigation needed in order to evaluate the impact that each of these companies has on the core Spanish economy. . In the UK, although has had a strong hit by COVID-19, the prices haven&#39;t significantly droped as in Italy and France. Some sectors though, such as beverages and forestry seemed that affected the most. Probably due to decrease in exports since the hospitality sector has been in inaction across Europe due to lockdown from the beginning of March. . In the USA, the country with the more incidents and deaths, the economic impact was hard if we focus on the drop of DOW 30 which decreased by 10000 units. Although, it has started increasing after mid March. It is still in significantly lower levels compare to pre-COVID 19 levels. S&amp;P 500 and NASDAQ on the other hand show a much smaller decrease of 1000 and 2000 units respectively. It also seems that they have already started recover loss as by end of April. The same applies for the rest of primary sectors. . In Brazil is recorded the highest drop of major index (Bovespa) among major indices. It records a drop of 47000 units. The major index contains the market stock prices of the major companies in a country, thus we can see that many of the powerful brazilian companies have been hit by COVID-19 crisis. It seems that companies operating in the electicity sector are among them as they record a drop of approximatelly 30000 units. Interesting fact that they seem to recover in a very slow pace. The rest of the sectors (included in the study) record small decreases. . Germany, has gotten a strong hit in its industrial sector in general showing a drop of 3000 units approximatelly without showing signs for fast recovery. The major german index (DAX) droped by approximately 6000 units since the beginining of the crisis. . It seems that the chemicals sector in Russia increased its prices during the COVID-19. On the other hand, financials, consumer and oil &amp; gas sectors affected the most during the COVID-19 period in the same country. . At last in Turkey sectors suchs food and beverages and chemicals and petrol seemed that had a high drop of 80000 and 50000 units respectively and then raise again to almost equal levels as pre-COVID 19 crisis. Apart from tourism which seems to be quite steady throughout the year the rest of the sectors record medium to high fluctuations during the COVID-19 time (March-April 2020). . Macroeconomic Analysis . In this part of the analysis we will look at the economic impact of the virus from a macroeconomic perspective. Macroeconomics is a branch of economics that studies how an overall economy behaves (focuses on the large scale). More presicely, macroeconomics studies economy-wide phenomena such as inflation, price levels, rate of economic growth, national income, gross domestic product (GDP), and changes in unemployment Investopedia 1. . In the graph below major countrys&#39; GDP, inflation and unemployment annual change rate data from IMF includings forecast of 2020 and 2021 are illustrated. . # collapse-hide # data preprocessing def extract_data(df, subject): dates = [&#39;2014&#39;, &#39;2015&#39;, &#39;2016&#39;, &#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;, &#39;2021&#39;] d = {&#39;Date&#39;: dates, &#39;Value&#39;: [df[date] for date in dates]} values = [] countries = [] _dates = [] for country in df.Country.unique(): tmp = df.loc[df.Country == country] for date in dates: countries.append(country) _dates.append(date) values.append(float(tmp[date])) rv = pd.DataFrame.from_dict({&#39;Date&#39;: _dates, &#39;Country&#39;: countries, &#39;Value&#39;: values}) rv[&#39;subject&#39;] = subject return rv unemploy = majorCountry.loc[majorCountry[&#39;Subject Descriptor&#39;] == &#39;Unemployment rate&#39;] unemploy = extract_data(unemploy, &#39;unemployment&#39;) inflation = majorCountry.loc[majorCountry[&#39;Subject Descriptor&#39;] == &#39;Inflation, average consumer prices&#39;] inflation = extract_data(inflation, &#39;inflation&#39;) gdp = majorCountry.loc[majorCountry[&#39;Subject Descriptor&#39;] == &#39;Gross domestic product, constant prices&#39;] gdp = extract_data(gdp, &#39;gdp&#39;) # A dropdown filter countries = list(majorCountry.Country.unique()) country_dropdown = alt.binding_select(options=countries) country_select = alt.selection_single(fields=[&#39;Country&#39;], bind=country_dropdown, name=&quot;Select&quot;,init={&#39;Country&#39;: &#39;United States&#39;}) filter_gdp = alt.Chart(gdp, width=300, height=300, title=&#39;GDP Growth of Major Countries&#39;).mark_line(point=True).encode( alt.X(&#39;Date:T&#39;), alt.Y(&#39;Value:Q&#39;, title= &#39;Growth Rate %&#39;), color=&#39;Country&#39;, tooltip = [alt.Tooltip(&#39;Value:Q&#39;)] ).add_selection(country_select).transform_filter(country_select) # umemployment plot filter_unemployment = alt.Chart(unemploy, width=300, height=300, title=&#39;Unemployment Change of Major Countries&#39;).mark_line(point=True).encode( alt.X(&#39;Date:T&#39;), alt.Y(&#39;Value:Q&#39;, title= &#39;Unemployment Rate %&#39;), color=&#39;Country&#39;, tooltip = [alt.Tooltip(&#39;Value:Q&#39;)] ).add_selection(country_select).transform_filter(country_select) # inflation plot filter_inflation = alt.Chart(inflation, width=300, height=300, title=&#39;Inflation Change of Major Countries&#39;).mark_line(point=True).encode( alt.X(&#39;Date:T&#39;), alt.Y(&#39;Value:Q&#39;, title= &#39;Inflation Rate %&#39;), color=&#39;Country&#39;, tooltip = [alt.Tooltip(&#39;Value:Q&#39;)] ).add_selection(country_select).transform_filter(country_select) (filter_gdp | filter_unemployment | filter_inflation) . . The projections of IMF for growth looks the same for all the countries. It seems, that COVID-19 crisis has affected the general economy of the under study countries significantly. We also received an initial impression about the countries&#39; economic overview from the stock market analysis. For Brazil for example which show the highest drop in its major stock index is projected a drop from 1% in 2019 to -5 in 2020%. Although, the signs for 2021 seems positive. The major EU countries, Spain, Italy, France and Germany they seem to have important drop as well which will reach a growth -8% on average for all them. While USA, UK and Russia will record a growth of -6%. Turkey will have growth of -4%. . Consequently, there will be an increase in unemployment rates. For countries like Spain it will even reach 20% recording an increase of 5% compared to 2019, while for Italy and France it will reach 10%-11%. In Germany although the unemployment rate will increase to 4% it is still in very low levels. The same applies for the UK and Russia where unemployment is expected to reach 5% in both. In the USA the unemployment will sky rocket from 4% in 2019 to 10% in 2020. In Brazil and Turkey seems that unemployment was raising continuously the last five years and is going to climb at 14% and 17% accordingly. . Ultimately, inflation is projected to drop for all the countries in 2020 apart from Brazil which will remain steady. Low inflation means that the prices of goods and services drops. Because, many goods/services are available and there is not enough money circulating to purchase those goods. As a result, the companies have forced to impose layoffs. According to Investopedia 1 the central banks aim to maintain the inflation/deflation between 2%-3% year. In this case that all the countries are within this range for 2020 and 2021(if nothing changes) according to IMF&#39;s projections. Thus, we would conclude that a general financial crisis can be avoided. . International trading . One of the important economic activites is international trading among different countries. In this section we would like to analysis whether the COVID-19 has an impact on trading activites. . By the end of 2019, major countries that are currently suffering from the virus were not being affected yet. So compare to previous seasons of 2019 the import and export volume didn&#39;t drop significantly. Some countries like Brazil and Russia even had an increase in imports. . However, by the end of first quarter of 2020, most major countries have taken some actions like travel limitation and lockdown which have a huge impact on international trading. . . Note: We collect the data from OECD, some of the coutries in the dataset include the data of first quarter of 2020, some of them are not. . A large decrease of both import and export of US can be observed at graph below. . #collapse-hide # data preprocessing trade = trade.replace({&#39;Imports in goods (value)&#39;: &#39;Imports&#39;, &#39;Exports in goods (value)&#39;: &#39;Exports&#39;}) # trade data doesn&#39;t include Spain countries = [&#39;Italy&#39;, &#39;United States&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Turkey&#39;, &#39;United Kingdom&#39;, &#39;Russia&#39;, &#39;Brazil&#39;] trade = trade.loc[trade.Country.isin(countries)] quarterlyTrade = trade.loc[trade.Frequency == &#39;Quarterly&#39;] monthlyTrade = trade.loc[trade.Frequency == &#39;Monthly&#39;] # a dropdown country_dropdown = alt.binding_select(options=countries) realPercent = alt.binding_radio(options=[&#39;Percentage&#39;, &#39;US Dollar&#39;]) country_select = alt.selection_single(name=&quot;Select&quot;, fields=[&#39;Country&#39;, &#39;Unit&#39;], bind={&#39;Country&#39;: country_dropdown, &#39;Unit&#39;: realPercent}, init={&#39;Country&#39;: &#39;United States&#39;, &#39;Unit&#39;: &#39;Percentage&#39;}) alt.Chart(quarterlyTrade).mark_bar().encode( x=&#39;Subject:O&#39;, y=alt.Y(&#39;Value:Q&#39;, title=&#39;Change Percentage(%) or Billion&#39;), color=alt.condition( alt.datum.Value &gt; 0, alt.value(&quot;steelblue&quot;), # The positive color alt.value(&quot;orange&quot;) # The negative color ), tooltip = [alt.Tooltip(&#39;Value:Q&#39;)], column=alt.Column(&#39;TIME:N&#39;, title=&#39;Date&#39;) ).add_selection(country_select).transform_filter(country_select) . . Conclusion . Overall, we saw how the COVID-19 has spread out around the globe and which countries have been affected the most. We noticed that 10 countries have been mainly hit by the virus. We found out that by summing up the number of cases of those countries compare to the rest of the world, the differences were significantly high. To be more presice we found out that these 10 coutnries count the 70% of all the confirmed cases and the 80% of all the deaths. There is no unique explanation on why such developed countries were inadequate to prevent the expansion of the virus while smaller less developed ones managed to accomplish that (e.g Greece). The major reason could be the hesitation of their leaders to implement stict measurements to isolate the virus due to fear on how such measurements could affect their economy. . In the economy part we saw that the the major indices and few of the primary sectors of the focus countries record significant drops on its prices. Countries like, Spain, France, Brazil, Italy and Germany seem to be in a steady low condition and don&#39;t seem to overcome the situation any time soon. Although, the show signs of slow recovery. On the other hand, UK, Russia, USA seems that move towards the pre-COVID 19 levels in faster pace. Meaning that the major companies in this countries show to adapt to the after COVID-19 era and overcome the initial shock that occured suddenly by the virus. . However, the COVID-19 situation has caused uncertainty as nobody knows how the future will be formed. This can be seen by the negative predictions of IMF in the macroeconomy of those countries in 2020. Although it&#39;s projected that the economy is going to get better in 2021. Since, the countries that have been affected the most by COVID-19 happens to be the most advanced economies the drop in their growth most likely will impact smaller economies as well. . Ultimately we can conclude that COVID-19 pandemic will strongly affect the total macroeconomy of the studied countries for 2020. Although, the stock market in general seems to slowly overcome the intial shock occured due to corona crisis. It has to be noted though that the stock market depicts the predominant companies in each country&#39;s economy. Usually they possess high capitals which will help them to overcome such a crisis faster than medium and small businesses. Thus, the former will probably be affected the most. . Genres . Following the guidance and explanations of narrative visualization as presented in Segal and Heer 2 we chose a combination of genres to present our case. To be more specific, we included visualizations such annotated graphs/map (genre 1) and slide show(Genre 2) format. . By chosing those genres we aimed to built an author and reader driven visualization report. Thus we used annotated graphs to convey our messages but we, also implemented interactive slide shows which allows to the reader/user to explore the results according to his/her will. . In regards to visual narrative we used progress bar/timebar in combination with animated transition to illustrate how the virus is spread throughout the countries in order to provide a more cohesive understainding of the speed of the virus expansion as well as to illustrate the impact of the virus in each country. We have also used feature distinction extensively in the economic assessment to distinguish among the different sectors presented in the graphs. The same applies in presentation of COVID-19 where we have highlighted the countries of interest by unique color. The same applies also in import/export graph where we illustrate with unique colors each feature. . At last as narrative structure we used filtering in order to save space and present the results in one graph while at the same time to give to the audience the possibility to choose to illustrate the features of interest. Additionally, annotations have been added in the majority of graphs where complete information given about the COVID-19 situation of the corresponding countries. In that way the reader can always have the necessary information about the feature of interest immediately. Also, in all the graphs headlines are depicted in order to remind to the reader what the graph illustrates. Introductory texts prior the graphs are provided throughout the report in order to give an introduction to the audiece on what they are going to be presented to. . Visualization . In this section we will give a summary of the visualizations included in the study and the reasons we chose them in order to present its outcome. . The first visual of the report is a map which illustrated the general COVID-19 condition worldwide. The idea was to present the map as a summary of the entire virus situation and give to auience an inital idea on what is going to follow in the first part of the study. . Then we continue with a barchart where we illustrate all the countries involved by the confirmed cases occured in each one. We decided to set a threshold of 100000 cases in order to narrow down the scope of the report. We also decided to color the bars according to the number of cases per country. In that way we will give the mangitude of the virus in regards to confirmed cases accross the countries in a more cohesive way than the map. . Later we illustrate the overall cases per country of focus. We show the cases in 3 different horizontal bar charts. In this way is illustrated clearly the information about deaths, recovered and confirmed cases. . When new data addded, we first wanted to show the spread of new cases across the countries throughout the time period of crisis in order to give an overview on how the virus has affected each country in per day basis. . Then we use again a horizontal bar chart to illustrate the average per day new deaths and so on, per country. . When we noticed that the death, recovery and infection rates differ among countries, we consdired wise to include a graph which illustrates those rates in order to understand better the impact the virus has in each country. We used filters so the reader can compare these rates per country. . In the last part of COVID-19 analysis we included an annimated transition graph in combination with a timebar. In this way we wanted to give the chance to the reader to watch the correlation among confirmed, deaths and recovered cases over time while, he has in mind the results from the overall analysis up to this point. . In the second part of the study, we illustrate the stock market indices per country in a multi-line chart. We use filter in order to distinguish among the countries. Also we use annotations and feature distinction in each graph in order to provide more information about individual indeces. This was the most clean and comprehensive way to present such results and provide an overview of the market. . For the macroeconmic analysis we use again line charts and implemented a filter in order the reader to be able to see the macroeconomic features per country. Three graphs placed parallel to each other for a better illustration. . At last the imports/exports are illustrated in bar char. In this way it is easy for the reader to see and compare the prices between the two. Double filter has applied here, so the reader can choose individual country and the unit of interest. . Discussion . We believe that we present a comprehensive and cohisive study about the economic impact of COVID-19. Also we have presented in a very analytical way the distribution of the virus.We approached the financial impact from many aspects by illustrating results of stocks for each primary sector in every country. GDP, inflation and unemployment of the corresponding countries as well as imports and exports. We have given a nice and easy to follow flow to the study, renders it therefore, easy for the reader to go through. At last, we believe that the graphs included in the study can give all the necessary information needed for the reader to get a quick overview of the report. . On the other hand it might be good to include more scatter plots in regards to statistics to illustrate outliers or correlation among the variables. Also, we would like to include more graphs that would illustrate the formation of the market in correlation with confirmed,death and recovered cases in one graph. We would like to go deeper in financial analysis and present it from a microeconomic perspective. We would like to include market prices of specific products to see how the shopping habbits have changed. Unfortunately we couldn&#39;t find enough data. We tried to sort of illustrate that with import/exports but still data for 2020 for all the countries are not available. . It was also a thought to carry out machine learning in order to predict the prices of the stocks the forecoming months as well as a prediction of future deaths etc. due to COVID-19. In the first case we didn&#39;t have enough time to conduct such as assessment while in the former too many assumptions should be taken under consideration for each country that would consitute the study inaqurate at great extend. . Contribution . Since we were only two members both have contributed equally in the outcome of the study. . Dividing the report in parts, coding being the first part and writting the other, the contribution formed as follows. . Yucheng Georgios . Coding | 60% | 40% | . Writing | 40% | 60% | . The coding part includes, data research, setting the website, typing and editing the code etc.. Writing includes the analysis in the text,the actual writing of it, the structure of the report and the text editing. . Data source . https://ilostat.ilo.org . https://www.investing.com . https://www.imf.org . http://www.oecd.org . https://github.com/datasets/covid-19 . Reference . 1. Investopedia↩ . 2. Segal and Heer↩ .",
            "url": "https://narcissist1.github.io/02806-final-project/data_analysis/visualization/2020/05/04/final-project-Short.html",
            "relUrl": "/data_analysis/visualization/2020/05/04/final-project-Short.html",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://narcissist1.github.io/02806-final-project/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://narcissist1.github.io/02806-final-project/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://narcissist1.github.io/02806-final-project/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://narcissist1.github.io/02806-final-project/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}